<!-- Copyright (c) 2020 ARM Limited. -->
<!--                                 -->
<!-- SPDX-License-Identifier: MIT    -->
<!--                                 -->
<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ArmNN: Introduction</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="ArmNN" src="Arm_NN_horizontal_blue.png" style="max-width: 10rem; margin-top: .5rem; margin-left 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">21.08</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Introduction </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><ul>
<li><a href="#software-tools-overview">Software tools overview</a></li>
<li><a href="#where-to-find-more-information">Where to find more information</a></li>
<li><a href="#contributions">Contributions</a></li>
<li><a href="#disclaimer">Disclaimer</a></li>
<li><a href="#license">License</a></li>
<li><a href="#third-party">Third-Party</a></li>
</ul>
<p>Arm NN is a key component of the <a href="https://mlplatform.org/">machine learning platform</a>, which is part of the <a href="https://www.linaro.org/news/linaro-announces-launch-of-machine-intelligence-initiative/">Linaro Machine Intelligence Initiative</a>.</p>
<p>The Arm NN SDK is a set of open-source software and tools that enables machine learning workloads on power-efficient devices. It provides a bridge between existing neural network frameworks and power-efficient Cortex-A CPUs, Arm Mali GPUs and Arm Ethos NPUs.</p>
<div class="image">
<img src="https://developer.arm.com/-/media/Arm Developer Community/Images/Block Diagrams/Arm-NN/Arm-NN-Frameworks-Diagram.png" align="center" width="400"/>
</div>
<p>Arm NN SDK utilizes the Compute Library to target programmable cores, such as Cortex-A CPUs and Mali GPUs, as efficiently as possible. To target Ethos NPUs the NPU-Driver is utilized. We also welcome new contributors to provide their <a class="el" href="md_src_backends__r_e_a_d_m_e.xhtml">own driver and backend</a>. Note, Arm NN does not provide support for Cortex-M CPUs.</p>
<p>The latest release supports models created with <b>TensorFlow Lite</b> (TfLite) and <b>ONNX</b>. Arm NN analysis a given model and replaces the operations within it with implementations particularly designed for the hardware you want to execute it on. This results in a great boost of execution speed. How much faster your neural network can be executed depends on the operations it contains and the available hardware. Below you can see the speedup we've been experiencing in our experiments with a few common networks.</p>
<div class="image">
<img src="https://developer.arm.com/-/media/developer/Other Images/Arm_NN_performance_relative_to_other_NN_frameworks_diagram.png" align="center" width="700"/>
</div>
<p>Arm NN is written using portable C++14 and the build system uses <a href="https://cmake.org/">CMake</a>, therefore it is possible to build for a wide variety of target platforms, from a wide variety of host environments.</p>
<h2>Getting started: Software tools overview</h2>
<p>Depending on what kind of framework (Tensorflow Lite, ONNX) you've been using to create your model there are multiple software tools available within Arm NN that can serve your needs.</p>
<p>Generally, there is a <b>parser</b> available <b>for each supported framework</b>. Each parser allows you to run models from one framework e.g. the TfLite-Parser lets you run TfLite models. You can integrate these parsers into your own application to load, optimize and execute your model. We also provide <b>python bindings</b> for our parsers and the Arm NN core. We call the result <b>PyArmNN</b>. Therefore your application can be conveniently written in either C++ using the "original" Arm NN library or in Python using PyArmNN. You can find tutorials on how to setup and use our parsers in our doxygen documentation. The latest version can be found in the <a href="https://github.com/ARM-software/armnn/wiki/Documentation">wiki section</a> of this repository.</p>
<p>Admittedly, building Arm NN and its parsers from source is not always easy to accomplish. We are trying to increase our usability by providing Arm NN as a <b>Debian package</b>. Our debian package is the most easy way to install the Arm NN Core, the TfLite Parser and PyArmNN (More support is about to come): <a class="el" href="md__installation_via_apt_repository.xhtml">Installation via Apt Repository</a></p>
<p>The newest member in Arm NNs software toolkit is the <b>TfLite Delegate</b>. The delegate can be integrated in TfLite. TfLite will then delegate operations, that can be accelerated with Arm NN, to Arm NN. Every other operation will still be executed with the usual TfLite runtime. This is our <b>recommended way to accelerate TfLite models</b>. As with our parsers there are tutorials in our doxygen documentation that can be found in the <a href="https://github.com/ARM-software/armnn/wiki/Documentation">wiki section</a>.</p>
<p>If you would like to use <b>Arm NN on Android</b> you can follow this guide which explains <a class="el" href="md__build_guide_android_n_d_k.xhtml">how to build Arm NN using the AndroidNDK</a>. But you might also want to take a look at another repository which implements a hardware abstraction layer (HAL) for Android. The repository is called <a href="https://github.com/ARM-software/android-nn-driver">Android-NN-Driver</a> and when integrated into Android it will automatically run neural networks with Arm NN.</p>
<h2>Where to find more information</h2>
<p>The section above introduces the most important tools that Arm NN provides. You can find a complete list in our <b>doxygen documentation</b>. The latest version can be found in the <a href="https://github.com/ARM-software/armnn/wiki/Documentation">wiki section</a> of our github repository.</p>
<p>For FAQs and troubleshooting advice, see <a class="el" href="md_docs__f_a_q.xhtml">FAQ.md</a> or take a look at previous <a href="https://github.com/ARM-software/armnn/issues">github issues</a>.</p>
<h2>Note</h2>
<ol type="1">
<li>The following tools have been removed in 21.05:<ul>
<li>TensorFlow Parser</li>
<li>Caffe Parser</li>
<li>Quantizer</li>
</ul>
</li>
<li>Ubuntu Linux 16.04 LTS is no longer supported from April 30, 2021. As a result Ubuntu 16.04 LTS will no longer receive security patches or other software updates. Consequently Arm NN will from the 21.08 Release at the end of August 2021 no longer be officially supported on Ubuntu 16.04 LTS but will instead be supported on Ubuntu 18.04 LTS.</li>
</ol>
<h2>How to get involved</h2>
<p>If you would like to get involved but don't know where to start, a good place to look is in our Github Issues.</p>
<p>Feature requests without a volunteer to implement them are closed, but have the 'Help wanted' label, these can be found <a href="https://github.com/ARM-software/armnn/issues?q=is%3Aissue+label%3A%22Help+wanted%22+">here</a>. Once you find a suitable Issue, feel free to re-open it and add a comment, so that other people know you are working on it and can help.</p>
<p>When the feature is implemented the 'Help wanted' label will be removed.</p>
<h2>Contributions</h2>
<p>The Arm NN project welcomes contributions. For more details on contributing to Arm NN see the <a href="https://mlplatform.org/contributing/">Contributing page</a> on the <a href="https://mlplatform.org/">MLPlatform.org</a> website, or see the <a class="el" href="md__contributor_guide.xhtml">Contributor Guide</a>.</p>
<p>Particularly if you'd like to implement your own backend next to our CPU, GPU and NPU backends there are guides for backend development: <a class="el" href="md_src_backends__r_e_a_d_m_e.xhtml">Backend development guide</a>, <a class="el" href="md_src_dynamic__r_e_a_d_m_e.xhtml">Dynamic backend development guide</a></p>
<h2>Disclaimer</h2>
<p>The armnn/tests directory contains tests used during Arm NN development. Many of them depend on third-party IP, model protobufs and image files not distributed with Arm NN. The dependencies of some of the tests are available freely on the Internet, for those who wish to experiment, but they won't run out of the box.</p>
<h2>License</h2>
<p>Arm NN is provided under the <a href="https://spdx.org/licenses/MIT.html">MIT</a> license. See [LICENSE](LICENSE) for more information. Contributions to this project are accepted under the same license.</p>
<p>Individual files contain the following tag instead of the full license text. </p><pre class="fragment">SPDX-License-Identifier: MIT
</pre><p>This enables machine processing of license information based on the SPDX License Identifiers that are available here: <a href="http://spdx.org/licenses/">http://spdx.org/licenses/</a></p>
<h2>Third-party</h2>
<p>Third party tools used by Arm NN:</p>
<table class="doxtable">
<tr>
<th>Tool </th><th>License (SPDX ID) </th><th>Description </th><th>Version </th><th>Provenience  </th></tr>
<tr>
<td>cxxopts </td><td>MIT </td><td>A lightweight C++ option parser library </td><td>SHA 12e496da3d486b87fa9df43edea65232ed852510 </td><td><a href="https://github.com/jarro2783/cxxopts">https://github.com/jarro2783/cxxopts</a> </td></tr>
<tr>
<td>doctest </td><td>MIT </td><td>Header-only C++ testing framework </td><td>2.4.0 </td><td><a href="https://github.com/onqtam/doctest">https://github.com/onqtam/doctest</a> </td></tr>
<tr>
<td>fmt </td><td>MIT </td><td>{fmt} is an open-source formatting library providing a fast and safe alternative to C stdio and C++ iostreams. </td><td>7.0.1 </td><td><a href="https://github.com/fmtlib/fmt">https://github.com/fmtlib/fmt</a> </td></tr>
<tr>
<td>ghc </td><td>MIT </td><td>A header-only single-file std::filesystem compatible helper library </td><td>1.3.2 </td><td><a href="https://github.com/gulrak/filesystem">https://github.com/gulrak/filesystem</a> </td></tr>
<tr>
<td>half </td><td>MIT </td><td>IEEE 754 conformant 16-bit half-precision floating point library </td><td>1.12.0 </td><td><a href="http://half.sourceforge.net">http://half.sourceforge.net</a> </td></tr>
<tr>
<td>mapbox/variant </td><td>BSD </td><td>A header-only alternative to 'boost::variant' </td><td>1.1.3 </td><td><a href="https://github.com/mapbox/variant">https://github.com/mapbox/variant</a> </td></tr>
<tr>
<td>stb </td><td>MIT </td><td>Image loader, resize and writer </td><td>2.16 </td><td><a href="https://github.com/nothings/stb">https://github.com/nothings/stb</a> </td></tr>
</table>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Tue Aug 24 2021 16:18:53 for ArmNN by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
