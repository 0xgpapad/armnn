<!-- Copyright (c) 2020 ARM Limited. -->
<!--                                 -->
<!-- SPDX-License-Identifier: MIT    -->
<!--                                 -->
<!-- HTML header for doxygen 1.8.13-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="robots" content="NOINDEX, NOFOLLOW" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ArmNN: Integrate the TfLite delegate into TfLite using Python</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <img alt="ArmNN" src="Arm_NN_horizontal_blue.png" style="max-width: 10rem; margin-top: .5rem; margin-left 10px"/>
  <td style="padding-left: 0.5em;">
   <div id="projectname">
   &#160;<span id="projectnumber">21.05</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_delegate__integrate_delegate_into_python.xhtml','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Integrate the TfLite delegate into TfLite using Python </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>If you have built the TfLite delegate as a separate dynamic library then this tutorial will show you how you can integrate it in TfLite to run models using python.</p>
<p>Here is an example python script showing how to do this. In this script we are making use of the <a href="https://www.tensorflow.org/lite/performance/implementing_delegate#option_2_leverage_external_delegate">external adaptor</a> tool of TfLite that allows you to load delegates at runtime. </p><div class="fragment"><div class="line">import numpy as np</div><div class="line">import tflite_runtime.interpreter as tflite</div><div class="line"></div><div class="line"># Load TFLite model and allocate tensors.</div><div class="line"># (if you are using the complete tensorflow package you can find load_delegate in tf.experimental.load_delegate)</div><div class="line">armnn_delegate = tflite.load_delegate( library=&quot;&lt;your-armnn-build-dir&gt;/delegate/libarmnnDelegate.so&quot;,</div><div class="line">                                       options={&quot;backends&quot;: &quot;CpuAcc,GpuAcc,CpuRef&quot;, &quot;logging-severity&quot;:&quot;info&quot;})</div><div class="line"># Delegates/Executes all operations supported by ArmNN to/with ArmNN</div><div class="line">interpreter = tflite.Interpreter(model_path=&quot;&lt;your-armnn-repo-dir&gt;/delegate/python/test/test_data/mock_model.tflite&quot;, </div><div class="line">                                 experimental_delegates=[armnn_delegate])</div><div class="line">interpreter.allocate_tensors()</div><div class="line"></div><div class="line"># Get input and output tensors.</div><div class="line">input_details = interpreter.get_input_details()</div><div class="line">output_details = interpreter.get_output_details()</div><div class="line"></div><div class="line"># Test model on random input data.</div><div class="line">input_shape = input_details[0][&#39;shape&#39;]</div><div class="line">input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)</div><div class="line">interpreter.set_tensor(input_details[0][&#39;index&#39;], input_data)</div><div class="line"></div><div class="line">interpreter.invoke()</div><div class="line"></div><div class="line"># Print out result</div><div class="line">output_data = interpreter.get_tensor(output_details[0][&#39;index&#39;])</div><div class="line">print(output_data)</div></div><!-- fragment --><h1>Prepare the environment</h1>
<p>Pre-requisites:</p><ul>
<li>Dynamically build Arm NN Delegate library</li>
<li>python3 (Depends on TfLite version)</li>
<li>virtualenv</li>
<li>numpy (Depends on TfLite version)</li>
<li>tflite_runtime (&gt;=2.0, depends on Arm NN Delegate)</li>
</ul>
<p>If you haven't built the delegate yet then take a look at the ./BuildGuideNative.md "build guide".</p>
<p>We recommend creating a virtual environment for this tutorial. For the following code to work python3 is needed. Please also check the documentation of the TfLite version you want to use. There might be additional prerequisites for the python version. </p><div class="fragment"><div class="line"># Install python3 (We ended up with python3.5.3) and virtualenv</div><div class="line">sudo apt-get install python3-pip</div><div class="line">sudo pip3 install virtualenv</div><div class="line"></div><div class="line"># create a virtual environment</div><div class="line">cd your/tutorial/dir</div><div class="line"># creates a directory myenv at the current location</div><div class="line">virtualenv -p python3 myenv </div><div class="line"># activate the environment</div><div class="line">source myenv/bin/activate</div></div><!-- fragment --><p>Now that the environment is active we can install additional packages we need for our example script. As you can see in the python script at the start of this page, this tutorial uses the <code>tflite_runtime</code> rather than the whole tensorflow package. The <code>tflite_runtime</code> is a package that wraps the TfLite Interpreter. Therefore it can only be used to run inferences of TfLite models. But since Arm NN is only an inference engine itself this is a perfect match. The <code>tflite_runtime</code> is also much smaller than the whole tensorflow package and better suited to run models on mobile and embedded devices.</p>
<p>At the time of writing, there are no packages of either <code>tensorflow</code> or <code>tflite_runtime</code> available on <code>pypi</code> that are built for an arm architecture. That means installing them using <code>pip</code> on your development board is currently not possible. The TfLite <a href="https://www.tensorflow.org/lite/guide/python">website</a> points you at prebuilt <code>tflite_runtime</code> packages. However, that limits you to specific TfLite and Python versions. For this reason we will build the <code>tflite_runtime</code> from source.</p>
<p>You will have downloaded the tensorflow repository in order to build the Arm NN delegate. In there you can find further instructions on how to build the <code>tflite_runtime</code> under <code>tensorflow/lite/tools/pip_package/README.md</code>. This tutorial uses bazel to build it natively but there are scripts for cross-compilation available as well. </p><div class="fragment"><div class="line"># Add the directory where bazel is built to your PATH so that the script can find it</div><div class="line">PATH=$PATH:your/build/dir/bazel/output</div><div class="line"># Run the following script to build tflite_runtime natively.</div><div class="line">tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh</div></div><!-- fragment --><p> The execution of the script creates a <code>.whl</code> file which can be used by <code>pip</code> to install the TfLite Runtime package. The build-script produces some output in which you can find the location where the <code>.whl</code> file was created. Then all that is left to do is to install all necessary python packages with <code>pip</code>. </p><div class="fragment"><div class="line">pip install tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/dist/tflite_runtime-2.3.1-py3-none-any.whl numpy</div></div><!-- fragment --><p>Your virtual environment is now all setup. Copy the final python script into a python file e.g. <code>ExternalDelegatePythonTutorial.py</code>. Modify the python script above and replace <code>&lt;your-armnn-build-dir&gt;</code> and <code>&lt;your-armnn-repo-dir&gt;</code> with the directories you have set up. If you've been using the ./BuildGuideNative.md "native build guide" this will be <code>$BASEDIR/armnn/build</code> and <code>$BASEDIR/armnn</code>.</p>
<p>Finally, execute the script: </p><div class="fragment"><div class="line">python ExternalDelegatePythonTutorial.py</div></div><!-- fragment --><p> The output should look similar to this: </p><div class="fragment"><div class="line">Info: ArmNN v23.0.0</div><div class="line"></div><div class="line">Info: Initialization time: 0.56 ms</div><div class="line"></div><div class="line">INFO: TfLiteArmnnDelegate: Created TfLite ArmNN delegate.</div><div class="line">[[ 12 123  16  12  11  14  20  16  20  12]]</div><div class="line">Info: Shutdown time: 0.28 ms</div></div><!-- fragment --><p>For more details on what kind of options you can pass to the Arm NN delegate please check <a href="src/armnn_external_delegate.cpp">armnn_delegate_adaptor.cpp</a>.</p>
<p>You can also test the functionality of the external delegate adaptor by running some unit tests: </p><div class="fragment"><div class="line">pip install pytest</div><div class="line">cd armnn/delegate/python/test</div><div class="line"># You can deselect tests that require backends that your hardware doesn&#39;t support using markers e.g. -m &quot;not GpuAccTest&quot;</div><div class="line">pytest --delegate-dir=&quot;&lt;your-armnn-build-dir&gt;/armnn/delegate/libarmnnDelegate.so&quot; -m &quot;not GpuAccTest&quot; </div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="useguides.xhtml">Integration Guides</a></li>
    <li class="footer">Generated on Mon May 10 2021 16:39:53 for ArmNN by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
